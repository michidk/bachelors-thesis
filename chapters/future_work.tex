% !TeX root = ../main.tex
\chapter{Future Work}\label{chapter:future-work}

In this thesis, three experiments were implemented, to show that the smartphone can indeed be used to assist in \ac{VR}. But during the development and after the evaluation, many problems and areas for improvement were discovered. 


\section{UBI Interact}\label{section:fw-ubii}

At the time of writing, a feature of \ac{UBII} called \enquote{muxer} was still in development. This multiplexing feature enables to write interactions that operate on multiple topics. Data of different topics can be combined, evaluated, changed and then published to different topics. It could be used to handle multiple smartphone connections on the server-side to further abstract the system.

To make use of multitouch displays, which are displays which detect multiple fingers on the display, the smart device client has to be adjusted. It has to be decided if a new format, which supports multiple touch events stored in an array, using multiple topics, or multiple posts to the same topic makes more sense.

Also, the virtual keyboard experiment could be further abstracted into \ac{UBII} interactions. Theoretically, the client could just sent the coordinates to an interaction, and a an object with instructions on how to display the virtual keyboard alongside the pressed character or action could be returned.


\section{Experiments}\label{section:fw-experiments}

The tracking problem when holding the phone upside down could be solved. This would be done by implementing a native client to overcome the limitations of the WebAPIs. This would also give access to system buttons and \ac{OS}-layer features. In the current implementation, the fullscreen would sometimes exit, because the border of the screen was touched or a notification appeared. A native application could block these.

The model viewer experiment could also incorporate the touchscreen, by allowing to move or change the size of the model.

Further pointing techniques like those from \citeauthor{Argelaguet.2013} can be explored and compared to further improve the usability of the laser pointer~\cite{Argelaguet.2013}.

The evaluation of the virtual keyboard experiment brought many issues to light. 
Values like the sensitivity of the movement detection and selection speed have to be adjusted. Also, as the participants suggested, additional feedback when a key was pressed should be implemented. A cursor should be added to the text input field.Adding support for using multiple fingers at once, would require the changes mentioned in Chapter~\ref{section:fw-ubii}.

Also in the virtual keyboard experiment, it makes sense to compare further text input methods. Users suggested an implementation like the SwiftKey\footnote{SwiftKey by Microsoft is an application for smartphones which allows to highly customize the keyboard and introduce swiping based typing. Website: \href{https://www.microsoft.com/swiftkey}{www.microsoft.com/swiftkey}}-keyboard. This keyboard implementation enables to type without lifting the finger. 

Force Touch\footnote{Force Touch (also known as \enquote{3D Touch}) is a touch display technology by Apple. Website: \href{https://developer.apple.com/ios/3d-touch/}{developer.apple.com/ios/3d-touch/}}, which can measure touch pressure intensities, introduces another possibility to implement a keyboard for \ac{VR}. The cursor is shown by slightly touching the screen. Instead of holding the current position, the user would just touch the screen with more intensity to select a key. 


\section{Positional Tracking}\label{section:fw-positional-tracking}

Write about positional tracking and related papers.