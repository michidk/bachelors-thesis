% !TeX root = ../main.tex
\chapter{Future Work}\label{chapter:future-work}

In this thesis, three experiments were implemented to show that the smartphone can indeed be used as an input device for \gls{VR}. However, despite the positive results, a lot of problems and areas for improvement were discovered. % , during the development and after the evaluation,


\section{UBI Interact}\label{section:fw-ubii}

At the time of writing, a multiplexing feature of \gls{UBII} called \enquote{Muxer} was still in development. This feature enables to write Interactions that operate on multiple Topics. Data of different Topics can be combined, evaluated, changed, and then published to other Topics. It could be used to handle multiple smartphone connections on the server-side to further abstract the system.

To make use of multitouch displays, which are displays which detect multiple fingers at the same time, the smart device client has to be adjusted. It has to be decided if a new format, which supports multiple touch events stored in an array, multiple topics, or multiple posts to the same topic, make more sense.

Also, the virtual keyboard experiment could be further abstracted into \gls{UBII} Interactions. Theoretically, the client could send the touch position to an Interaction. The Interaction then returns instructions on how to display the virtual keyboard alongside the pressed character or action.


\section{Experiments}\label{section:fw-experiments}

The tracking problem when holding the smartphone upside down is yet unsolved. Implementing a native client to overcome the limitations of the Web\glspl{API}, solves this problem. This also gives access to system buttons and other \gls{OS}-layer features. In the current implementation, the fullscreen would sometimes exit, because the border of the screen was touched or a notification appeared. A native application could also block these.

The model viewer experiment can be further extended, to incorporate the touch-screen by allowing to move or change the size of the model.

Further pointing techniques like those from \citeauthor{Argelaguet.2013} can be explored and compared to further improve the usability of the laser pointer~\cite[123]{Argelaguet.2013}.

The evaluation of the virtual keyboard experiment brought many issues to light. 
Values like the sensitivity of the movement detection and selection speed have to be adjusted. Also, as the participants suggested, additional feedback when a key was pressed should be implemented. A caret may be added to the text input field, too. Adding support for using multiple fingers at once, requires the changes mentioned in Chapter~\ref{section:fw-ubii}, but would increase typing speed as well as usability.

Further, it makes sense to compare other text input methods. Users suggested an implementation like the \enquote{SwiftKey}\footnote{SwiftKey by Microsoft is an application for smartphones which allows to customize the keyboard and introduce swiping based typing. Website: \href{https://www.microsoft.com/swiftkey}{www.microsoft.com/swiftkey}}-keyboard. Also the implementation from \citeauthor{Shibata.2016} called \enquote{DriftBoard} can be assessed~\cite{Shibata.2016}. These keyboard implementations enable to type without lifting a finger. 

Force Touch\footnote{Force Touch (also known as \enquote{3D Touch}) is a touch display technology by Apple. Website: \href{https://developer.apple.com/ios/3d-touch/}{developer.apple.com/ios/3d-touch/}}, which measures touch pressure intensities, introduces another possibility to implement a keyboard for \gls{VR}. The cursor is shown when slightly touching the touch-screen. Instead of holding the current position, the user would touch the screen with more intensity to select a key. 

%This problem could also be solved by mounting a Leap Motion sensor to the \gls{HMD}.
\citeauthor{Afonso.2017} evaluated the use of a Leap Motion sensor mounted to \gls{HMD}, to track the finger movements on a smartphone display. Participants of their user study made fewer errors when using the implementation with a virtual avatar of the hand~\cite[247\psq]{Afonso.2017}. This is especially useful for the virtual keyboard. A regular smartphone keyboard can be used since the preview of the touch location do not have to be tracked by the touch display.

Only three \gls{VR} interactions were implemented in this thesis, but there are a lot more and more complex interactions -- for example, the manipulation or placement of three-dimensional objects in a \gls{VE}. Also, drawings or voice input are interactions which could be implemented using a smartphone. % chktex 8

The three experiments used the smartphone to send information from the phone to the \gls{HMD}. However, also the other direction can improve \gls{VR} experiences. Providing feedback using the vibrational motors or speakers of the smartphone is conceivable.


\section{Positional Tracking}\label{section:fw-positional-tracking}

All experiments, presented in this thesis, either do not have a virtual representation of the smartphone or a representation where just the rotation is synchronized. The smartphone's position cannot be accurately tracked out of the box, as discussed in Chapter~\ref{chapter:introduction}.

When using the Valve Index Base Stations or similar\footnote{The HTC Vive Base Stations or the HTC Vive Pro Base Stations would work as well.}, the Vive Tracker\footnote{The Vive Tracker is a generic tracker, which uses the same technology as the motion controllers. Website: \href{https://www.vive.com/eu/vive-tracker/}{www.vive.com/eu/vive-tracker/}} could be used to track the smartphone. However, the system should be generic and not bound to one particular tracking system. Also, the tracker would have to be attached to the smartphone, which makes it clumsy.

Since most \glspl{HMD} have a camera built-in, a marker could be displayed on the smartphone's screen. This marker could then be tracked by the camera of the \gls{HMD}. However, since the positions and view frustums of the cameras vary, this system has to be adjusted to every headset.

The system of \citeauthor{Dias.2018} which is presented in Chapter~\ref{section:dias-2018}, proposes a system, where the front camera of the smartphone is used to track a marker which is stuck to the \gls{HMD}~\cite[4]{Dias.2018}. Additionally, the system from \citeauthor{Afonso.2017} is used to track the hand and fingers with a Leap Motion sensor~\cite[247]{Afonso.2017}.

