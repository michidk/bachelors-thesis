% !TeX root = ../../main.tex
\section{Overview}\label{section:evaluation-overview}

To show that the smartphone is a suitable interaction device in use with \gls{VR}, the results of the user study are presented. Tasks were implemented into the three experiments, to measure the usability. Also, a \gls{SUS} user study was performed, to get feedback from the users.

The procedure of the user study was as follows:
\begin{enumerate}
  \item Introduce the user to the topic
  \item Let the user fill out the consent form
  \item Let the user fill out the preliminary questions
  \item Randomly choose an order for the experiments
  \item Hand the user the \gls{HMD} and smartphone
  \item For each experiment:
  \begin{enumerate}
    \item Brief the user for the experiment
    \item Let the user play around in the experiment, to get a feel for the interaction
    \item Start the task after a minute
    \item Save the anonymized task results
    \item Question the user the usability questions
  \end{enumerate}
\end{enumerate}

The evaluation was conducted in two different locations at different times of the day. Before starting the study, the \gls{WLAN} connection and network performance were tested and evaluated as appropriate. The specifications of the \gls{PC}, \gls{HMD} and smartphone of the different evaluation setups, is listed in the Appendix~\ref{chapter:append-user-eval-devices}. The \gls{PC} was able to run the application smoothly with an average of 60 frames per second, which is enough to run a smooth \gls{VR} experience. The \gls{WLAN} connection and devices were capable of 20 Mbps\footnote{Mbps stands for megabits per second. This unit is often used in reference to internet speeds.}, which is enough for synchronizing data without a noticeable lag.

Before starting the experiments, demographic questions had to be answered by the participants. The preliminary questions also asked to rate the use of specific technologies and statements on a Likert scale\footnote{A Likert scale is a type of rating scale which ranges from \enquote{Strongly disagree} to \enquote{Strongly agree}.}. 

After each experiment, a \gls{SUS} survey was conducted. The \acrfull{SUS} uses a set of 10 questions, which are rated from strongly disagree (1) to strongly agree (5), to assess the usability of a system~\cite[3]{Brooke.1996}. \citeauthor{Finstad.2006}'s suggestions to change the eighth question to make it easier understandable for non-native speakers was implemented~\cite[188]{Finstad.2006}. The evaluation form, which includes the preliminary questions and \gls{SUS} study, can be found in Appendix~\ref{chapter:append-user-eval-form}.

A final score, ranging from zero to 100, is then calculated from the individual answers~\cite{Brooke.1996}. \citeauthor{Bangor.2009} proposes a grading system for \gls{SUS} scores, which maps a value to a letter of the typical American school grading scale~\cite{Bangor.2009}. This system is used to asses the meaning of the score.

Useful metrics were collected while users performed the tasks. The anonymized metric data contained timing and interaction specific statics. The following statistics were collected:
\begin{enumerate}
  \item Model Viewer Experiment
  \begin{enumerate}
    \item Count of matched proposes
    \item Date and time
  \end{enumerate}

  \item Laser Pointer Experiment
  \begin{enumerate}
    \item Count of clicks (touched touch screen)
    \item Count of hits (hit a cube)
    \item Date and time
  \end{enumerate}
  
  \item Virtual Keyboard Experiment
  \begin{enumerate}
    \item Count of backspace presses (undo operations)
    \item Time it took to write the given sentence
    \item Date and time
  \end{enumerate}
\end{enumerate}
The data was saved in the JSON format and downloaded automatically after completing a task.